{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. opencv"
      ],
      "metadata": {
        "id": "Zye7b9dKORJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 basic"
      ],
      "metadata": {
        "id": "HwRgmWyvOVFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "V0YAasTjJlBP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgBGR=cv2.imread(fileName, cv2.IMREAD_COLOR) #인수 안넣어주면 이미지 그대로 읽어옴\n",
        "imgRGB=cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB) #color space를 바꾸어줌 #opencv는 bgr, matplotlib은 rgb\n",
        "imgGray=cv2.imread(fileName, cv2.IMREAD_GRAYSCALE) #cv2.IMREAD_UNCHANGED로 읽어오면 png에서 alpha채널 읽어옴\n",
        "\n",
        "plt.axis('off') #xy pixel 좌표 끔\n",
        "plt.imshow(imgGray, cmap='gray',interpolation='bicubic',asepct='auto') # 알아서 interpolation을 해줌 default antialiased, 'auto' 비율 바꿀 수 있음\n",
        "plt.show() #interpolation 이미지 해상도를 키웠을때 공백을 채워줌 기본적으로는 선형\n",
        "\n",
        "cv2.namedWindow('img',cv2.WINDOW_FREERATIO) # WINDOW_FULLSCREEN\n",
        "cv2.imshow('imgBGR',imgBGR) #namedwindow 안해주어도 알아서 창 만들고 띄어주긴함\n",
        "\n",
        "loop=True\n",
        "while (loop):\n",
        "    inKey=cv2.waitKey() #무한 대기, 값 넣어주면 ms단위로 시간지나면 꺼짐 #기본적으로 키 입력 한 번 받는거라 while로 돌려주어야함\n",
        "    if inKey==ord('q'):#ord(' ') #spacebar의 ascii, esc는 문자로 표현 안되어서 27로 직접넣음\n",
        "        #cv2.destroyAllWindows()\n",
        "        cv2.destroyWindow('img')\n",
        "        loop=False\n",
        "\n",
        "cv2.destroyAllWindows() # 열린 창 닫아주어야함, 부하걸림\n",
        "\n",
        "cv2.imwrite('filename.jpg',imgBGR,[cv2.IMWRITE_JPEG_QUALITY,85]) #이미지 저장, jpg 정보 유지율"
      ],
      "metadata": {
        "id": "HKjMeoqVWVBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture(0) # 0은 연결된 카메라 번호, 경로로 영상 지정\n",
        "\n",
        "a1=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #왜 int?\n",
        "a2=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH,640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT,480)\n",
        "\n",
        "while(True):\n",
        "    retval, frame = cap.read() # 호출할 때 마다 한 프레임씩 읽어옴\n",
        "    if not retval:\n",
        "        break\n",
        "    cv2.imshow('frame',frame)\n",
        "\n",
        "    key = cv2.waitKey(100) # 10fps니까 100ms 대기, 프레임 한장씩 넘기면서 영상 만들어줌\n",
        "    if key==27: # ascii에서 esc가 27임\n",
        "        break\n",
        "\n",
        "if cap.isOpened():\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "Ev9mgAUOM_Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "framesize=(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))) #tuple\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') #codec\n",
        "out1 = cv2.VideoWriter('data/record0.mp4',fourcc,fps,framesize)\n",
        "out2 = cv2.VideoWriter('data/record2.mp4',fourcc,fps,framesize, isColor=False)\n",
        "\n",
        "while (True):\n",
        "    retval, frame = cap.read()\n",
        "\n",
        "    if not retval:\n",
        "        break\n",
        "\n",
        "    out1.write(frame)\n",
        "\n",
        "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    out2.write(gray)\n",
        "\n",
        "    cv2.imshow('frame',frame)\n",
        "    cv2.imshow('gray',gray)\n",
        "\n",
        "if cap.isOpened():\n",
        "    cap.release()\n",
        "    out1.release()\n",
        "    out2.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "9NVgOg0RqjVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = cv2.calcHist([src1],[0],None,[256],[0,256]) #np.ndarray\n",
        "#이미지, 0번채널(grayscale), 마스크여부 ,hitsize 몇개로 나누는지 ,range\n",
        "plt.plot(hist)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vewGdk9LWUae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mask\n",
        "\n",
        "cv2.copyTo(src,mask,dst)\n",
        "#dst 출력영상 src와 크기 및 타입이 같은 dst를 넣어주면 새로 생성하지 않고 연산 수행\n",
        "#그렇지 않으면 dst새로 생성해서 return\n",
        "\n",
        "h,w=mask.shape[:2]\n",
        "crop= dst[10:10+h, 10:10+w] # image size 보고 이미지 넣을 위치\n",
        "# 얕은 복사라서 crop을 바꾸면 dst가 바뀜!!\n",
        "\n",
        "dst3=cv2.copyTo(src,mask,crop) # mask연산은 mask크기만큼만\n",
        "#src,mask,crop은 다 같은 크기여야함"
      ],
      "metadata": {
        "id": "k7bIqN1Njl2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hsv 색공간에서 영역을 검출해서 합성 rgb로는 어디까지가 녹색인지 명확히 하기힘듬\n",
        "#색공간을 바꾸어서 채도,명도 조절 및 명확한 연산이 가능\n",
        "hsv= cv2.cvtColor(frame1,cv2.COLOR_BGR2HSV)"
      ],
      "metadata": {
        "id": "OiVS1-t2UUqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 filter"
      ],
      "metadata": {
        "id": "wZl-FP6tOX1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst=cv2.add(src,50) #포화연산, rgb채널에서는 밝기조절역할\n",
        "dst=cv2.substract(src,50) #포화연산\n",
        "dst=cv2.multiply(src,2) # 차이가 벌어져서 대비가 뚜렷해짐\n",
        "dst=cv2.divide(src,src2,scale=255) # 나눈 결과에 255을 곱해서 밝기보정\n",
        "dst=cv2.divide(gray, blr, scale=255)# blr된 것으로 나누어서 255를 곱해주면 엣지는 원래값보다 작은 값으로 나누어지고 255를 곱해주면 선명해짐"
      ],
      "metadata": {
        "id": "uTKb0QZDPjPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst= cv2.addWeighted(src1, alpha=0.9, src2, beta=0.1, gamma=0) #gamma 가중합 결과에 더해줄 상수항,밝기조절, 포화연산\n",
        "\n",
        "#blending\n",
        "sharpened = cv2.addWeighted(img, 1.5, bilateral, -0.5, 0) #blur된 이미지 즉 엣지부분이 사라진 저주파부분만 빼주면서 고주파(엣지)가 강조됨"
      ],
      "metadata": {
        "id": "zSP0MK4VKwJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.bilateralFilter(src,-1,10,5) # 주변의 픽셀을 사용해서 연산을 부드럽게 해줌, 엣지(선)는 살리고 안 면부분 피부같은 것이 부드러워짐\n",
        "#양방향 필터는 픽셀 간의 공간적 근접성과 강도 유사성(비슷한 밝기,색상에 가중치 더 줌)을 모두 고려하여 작동한다.\n",
        "#d: 필터직경, 필터가 고려하는 주변 픽셀들의 거리, -1을 넣으면 sigmaSpace 기반으로 자동으로 계산, 보통 5~9 사\n",
        "#sigmaColor: 색 공간에서의 필터 강도. 이 값이 클수록 색상차이가 큰 색상도 고려하여 평균을 계산 즉 엣지가 더 흐려\n",
        "#sigmaSpace: 공간 거리에서의 필터 강도. 값이 클수록 더 멀리 있는 픽셀들도 필터에 포함\n",
        "#디테일이 많은 이미지에서는 d와 sigmaColor값을 줄인다."
      ],
      "metadata": {
        "id": "Nt2oB-mMLuwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.blur(src,(3,3)) #kernal size\n",
        "cv2.GaussianBlur(src,(3,3),0) #kernal size, sigmaX, simgaX(분산)로 blurring 조절\n",
        "# kernal size(0,0)하면 sigmax에 맞춰서 자동, 반대도 같은 논리, sigmaY생략 시 sigmaX=sigmaY\n",
        "dst=cv2.medianBlur(src,3) #image는 주변 픽셀간의 큰 차이가 나는 경우가 거의 없다 서서히 변하는게 보통 논리"
      ],
      "metadata": {
        "id": "4QaoDIQROq_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.fastNlMeansDenoisingColored(src, None, 10, 10, 7, 21)\n",
        "#h=10 밝기채널 노이즈 제거 필터 강도\n",
        "#hColor=10 컬러 이미지 채널간의 노이즈 제거 강도 보통 h와 같거나 작은값, 색상정보가 보통 더 민감하고 너무 크게 필터링하면 색상간의 경계가 흐려져서 색상번짐\n",
        "#templateWindowSize=7: 노이즈 제거에 사용할 주변 픽셀들의 크기, searchWindowSize=21: 픽셀 주변에서 유사한 패턴을 찾을 검색 영역의 크기"
      ],
      "metadata": {
        "id": "D01l5bqTqS_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#high-pass filter\n",
        "mask = np.asarray([[0,-0.5,0],[-0.5,3,-0.5],[0,-0.5,0]], dtype = np.float32) #모든 값의 합이 1이므로 전체 이미지의 밝기 유지\n",
        "sharpening_img = cv2.filter2D(dst,-1, mask)"
      ],
      "metadata": {
        "id": "HrQ92BurqdOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = cv2.imread('road.png',cv2.IMREAD_GRAYSCALE)\n",
        "dst = cv2.Canny(src,64,128) # threshold 2개를 주어야함, 윤곽 읽어올 때 용이\n",
        "# 검출하고싶은부분만 마스킹해서 딴 다음에 차선 주변의 노이즈만 처리"
      ],
      "metadata": {
        "id": "Qvy9B04WQr8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bgr_planes=cv2.split(src) #bgr채널 분리\n",
        "filtered_img = cv2.merge([bgr[0], bgr[1], bgr[2]]) # 합치기"
      ],
      "metadata": {
        "id": "7Pft4HSdP6G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#선형변환\n",
        "cv2.convertScaleAbs(src, alpha=1.1, beta=10)\n",
        "# alpha Contrast control (1.0-3.0), beta Brightness control (-100 to 100)"
      ],
      "metadata": {
        "id": "GtdWoczRrs45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contrast\n",
        "cv2.normalize(src,None,0,255,cv2.NORM_MINMAX)\n",
        "#없는 정보를 만드는것이 아니라 정보간격을 최대한 벌려서(분포를 바꾸어서) 사람눈으로 식별 용이하게 만듬\n",
        "dst = cv2.equalizeHist(src)\n",
        "#정규화는 일정한 간격으로 벌려주는 것, equalizerHist는 데이터 수치가 높은 구간은 간격이 넓게 수치가 적은부분은 간격이 좁게 중요한것이 더 대비되게, edge가 더 선명하게 살아남"
      ],
      "metadata": {
        "id": "Gs6xKMolVn1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.bitwise_and() #같은 위치의 두 픽셀의 비트가 모두 1인 경우 1, 두 값이 모두 1이 아닐 경우 0\n",
        "cv2.bitwise_and(image, image, mask=mask) #mask 흰색 부분만 bitwise_and 연산 수행\n",
        "cv2.bitwise_or() #같은 위치의 두 픽셀 중 한 개가 1인 경우 1, 두 값이 모두 1이 아닐 경우 0\n",
        "cv2.bitwise_xor() #같은 위치의 두 픽셀의 값이 다른 경우 1, 같으면 0\n",
        "cv2.bitwise_not() #비트, 이미지 색상 반\n",
        "dst = cv2.resize(dst, (w, h), interpolation=cv2.INTER_NEAREST)"
      ],
      "metadata": {
        "id": "FZu8_RKXRCYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 대비조절, np.float32, np.uint8 바꾸어주기\n",
        "img_float = result.astype(np.float32) / 255.0\n",
        "img_float = img_float * 0.7\n",
        "img_adjusted = (img_float * 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "lDI1jCh8sUuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unsharp masking\n",
        "kernel_size=(5,5) # 블러의 범위. (야간 사진에서는 3,3의 작은 사이즈)-> 이미 조도가 낮아 노이즈가 많고 디테일이 부족한 상황 -> 디테일 손실을 최소화해야함.\n",
        "sigma = 1.0 # Gaussian blur의 강도\n",
        "amount = 1.0 # 선명도의 강도, 높을수록 선명해지지만 노이즈도 증가\n",
        "blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
        "sharpened = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)"
      ],
      "metadata": {
        "id": "QSuJp3s0wBey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold, mask = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)# 100:threshold, 255:threshold넘었을 때 넣어줄 값\n",
        "#cv2.THRESH_BINARY: 픽셀 값이 임계값을 넘으면 maxval, 넘지 않으면 0 / cv2.THRESH_BINARY_INV 반대논리"
      ],
      "metadata": {
        "id": "jp6u_oWeDy8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 마스크를 이용하여 노이즈 제거된 이미지 합성\n",
        "dn1_img = np.where(mask[:, :, np.newaxis] == 255, dn1, src)"
      ],
      "metadata": {
        "id": "pOX24UepPxQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saturation\n",
        "saturation_factor = 0.7 # 채도 감소 비율 (0 ~ 1 사이의 값, 0: 완전 흑백, 1: 원본 채도)\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)# HSV 색 공간으로 변환\n",
        "hsv[:, :, 1] = hsv[:, :, 1] * saturation_factor\n",
        "saturation_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)# 다시 BGR 색 공간으로 변환"
      ],
      "metadata": {
        "id": "cI1XGHUpSL9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.3 input받아오기"
      ],
      "metadata": {
        "id": "WBWNvufHOjkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trackbar\n",
        "def on_trackbar(pos): #인수로 pos를 받아오기 때문에 trackbar가 1개이면 getTrackbarPos없이 그 위치 값 그대로 쓸 수 있음\n",
        "#두 개이상부터는 입력받은 pos가 어떤 trackbar인지 식별필요\n",
        "    hmin = cv2.getTrackbarPos('H_min','Trackbar') # 마우스 입력을 받아옴\n",
        "    hmax = cv2.getTrackbarPos('H_max','Trackbar')\n",
        "\n",
        "    # inrange함수 적용\n",
        "    dst = cv2.inRange(src, (hmin,0,0),(hmax,255,255)) # 두 threshold 사이에 있으면 1 아니면 0 바이너리로 리턴해줌\n",
        "    cv2.imshow('Trackbar',dst)\n",
        "\n",
        "cv2.namedWindow('Trackbar') # 창에 트랙바를 넣으려면 일단 창이 있어야함\n",
        "\n",
        "#call-back 함수 어떤 이벤트가 발생했을 때 이벤트에 따라 호출되는 함수\n",
        "cv2.createTrackbar('H_min','Trackbar',0,180,on_trackbar)\n",
        "cv2.createTrackbar('H_max','Trackbar',180,180,on_trackbar)\n",
        "cv2.setTrackbarPos('H_min','Trackbar',40) #마우스 입력대신 직접 값 넣어줄 때"
      ],
      "metadata": {
        "id": "PwyT73rYJuC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.4 image making"
      ],
      "metadata": {
        "id": "e4JtIjqWexwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.full((400,400,3),255, np.uint8) # 400x400x3 공간을 전부 255로 채움 흰색캔버스\n",
        "\n",
        "cv2.putText(img, text, (50,350),cv2.FONT_HERSHEY_SIMPLEX,3,(0,0,255),2,cv2.LINE_AA)\n",
        "#(50,350)입력 좌표 텍스트박스 좌측하단기준, 3 fontsize, (0,0,255) 색깔, 2 font 두께\n",
        "\n",
        "pt1=(50,100)\n",
        "pt2=(img.shape[0]-50, img.shape[1]-100)\n",
        "cv2.line(img, pt1, pt2, (0,0,255),3,cv2.LINE_4)\n",
        "# linetype8 은 대각선은 좀 표면이 거칠음 AA가 부드러움\n",
        "# 꺼끌꺼끌해지면 연산량 적어짐 부드러우면 선을 많이 긋는거라 연산많아짐\n",
        "# 보통 글씨 쓸때는 AA 많이씀\n",
        "qt1=(30,70)\n",
        "qt2=(50,100)\n",
        "# (x1,y1) (x2,y2)\n",
        "cv2.rectangle(img, qt1, qt2, (0,0,255), 1, cv2.LINE_4) #두께를 -1로 하면 안을 채움\n",
        "# x,y,width,height\n",
        "cv2.rectangle(img, (30,70,100,100),(255,0,0), 1, cv2.LINE_4)\n",
        "\n",
        "cv2.circle(img, qt1, 30 ,(0,255,0),2,cv2.LINE_AA) # 좌표값은 int 여야함. 픽셀위치니까"
      ],
      "metadata": {
        "id": "9Fck_fiMe10Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.5 etc"
      ],
      "metadata": {
        "id": "NGWFcEUkOdaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst1 = np.clip(src+100,0,255).astype(np.uint8) # 범위를 0에서 255 지정하고 연산 수행, 최소,최대치 한정, 0~255 사이에 위치하도록 안전망 역할"
      ],
      "metadata": {
        "id": "Vtv2mKqXPfvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixmin, pixmax,a,b = cv2.minMaxLoc(src) # a,b 최소 최대 위치"
      ],
      "metadata": {
        "id": "2LedUmvdVe11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors=['b','g','r']\n",
        "bgr_planes=cv2.split(src) # tuple형태로 나옴, numpy array배열이 하나씩 나누어져서 나옴\n",
        "\n",
        "for (p,c) in zip(bgr_planes,colors):\n",
        "  hist=cv2.calcHist([p],[0],None,[256],[0,256])\n",
        "  plt.plot(hist,color=c)#color 그래프 그릴때 색상 지정"
      ],
      "metadata": {
        "id": "jOgvDuMwVyri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow() #colab"
      ],
      "metadata": {
        "id": "HC5oHXYKXNXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.countNonZero() # 0이 아닌 픽셀의 개수, grayscale"
      ],
      "metadata": {
        "id": "dJBXz1sZpAmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = np.ones((5, 5), np.uint8) # (5,5)배열을 1로 채움"
      ],
      "metadata": {
        "id": "EVxaT4CvEXsA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}